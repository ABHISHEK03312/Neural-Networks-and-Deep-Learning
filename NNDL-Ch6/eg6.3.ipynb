{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chapter 6, example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating the figures folder\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Model, layers, models\n",
    "import pylab\n",
    "import utils\n",
    "import os\n",
    "\n",
    "if not os.path.isdir('figures'):\n",
    "    print('creating the figures folder')\n",
    "    os.makedirs('figures')\n",
    "    \n",
    "# Check the version of Tensorflow (2.2.0)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 28, 28)\n",
      "(2000, 28, 28)\n",
      "(12000, 28, 28, 1)\n",
      "(2000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare the MNIST dataset. \n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# choose 12000 images for training, 2000 images for testing\n",
    "x_train,y_train = x_train[:12000],y_train[:12000]\n",
    "x_test,y_test = x_test[:2000],y_test[:2000]\n",
    "# Convert the samples from integers to [0,1]\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `tf.data` to batch and shuffle the dataset:\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(128)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built Model\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Convert the samples from integers to [0,1]\n",
    "        # layers.experimental.preprocessing.Rescaling(1./255, input_shape=(28, 28, 1)),\n",
    "        # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "        self.conv1 = layers.Conv2D(32, 5, padding='SAME', activation='relu', use_bias=True)\n",
    "        # First Pooling layer - downsamples by 2X.\n",
    "        self.p1 = layers.MaxPool2D(pool_size=(2, 2), strides=(2,2), padding='SAME')\n",
    "        # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "        self.conv2 = layers.Conv2D(64, 5, padding='SAME', activation='relu', use_bias=True)\n",
    "        # Second Pooling layer - downsamples by 2X.\n",
    "        self.p2 = layers.MaxPool2D(pool_size=(2, 2), strides=(2,2), padding='SAME')\n",
    "        # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "        # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.d1 = layers.Dense(1024, activation='relu')\n",
    "        # dropout layer\n",
    "        self.drop = tf.keras.layers.Dropout(0.2)\n",
    "        # softmax\n",
    "        self.d2 = layers.Dense(10, activation='softmax')\n",
    "    def call(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        p1 = self.p1(conv1)\n",
    "        conv2 = self.conv2(p1)\n",
    "        p2 = self.p2(conv2)\n",
    "        flatten = self.flatten(p2)\n",
    "        d1 = self.d1(flatten)\n",
    "        drop = self.drop(d1)\n",
    "        out = self.d2(drop)\n",
    "        return conv1, p1, conv2, p2, out\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an optimizer and loss function for training\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select metrics to measure the loss and the accuracy of the model. \n",
    "# These metrics accumulate the values over epochs and then print the overall result.\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train step\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        _,_,_,_,predictions = model(images)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test step\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    _,_,_,_,predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3008114124866244, Accuracy: 0.11333333333333333, Test Loss: 2.29584963619709, Test Accuracy: 0.1055\n",
      "Epoch 2, Loss: 2.2881982935235854, Accuracy: 0.13675, Test Loss: 2.284812942147255, Test Accuracy: 0.131\n",
      "Epoch 3, Loss: 2.275294671667383, Accuracy: 0.17416666666666666, Test Loss: 2.273232638835907, Test Accuracy: 0.1825\n",
      "Epoch 4, Loss: 2.261491575139634, Accuracy: 0.25533333333333336, Test Loss: 2.2605641931295395, Test Accuracy: 0.2915\n",
      "Epoch 5, Loss: 2.246115430872491, Accuracy: 0.36825, Test Loss: 2.246188059449196, Test Accuracy: 0.378\n",
      "Epoch 6, Loss: 2.2283794651640223, Accuracy: 0.4464166666666667, Test Loss: 2.229211390018463, Test Accuracy: 0.428\n",
      "Epoch 7, Loss: 2.207147943212631, Accuracy: 0.4969166666666667, Test Loss: 2.208525776863098, Test Accuracy: 0.465\n",
      "Epoch 8, Loss: 2.1808205969790193, Accuracy: 0.5289166666666667, Test Loss: 2.1825934052467346, Test Accuracy: 0.5045\n",
      "Epoch 9, Loss: 2.1476776346247246, Accuracy: 0.573, Test Loss: 2.149418607354164, Test Accuracy: 0.5435\n",
      "Epoch 10, Loss: 2.104942413086587, Accuracy: 0.6074166666666667, Test Loss: 2.106179788708687, Test Accuracy: 0.566\n",
      "Epoch 11, Loss: 2.04862616797711, Accuracy: 0.6269166666666667, Test Loss: 2.0486875474452972, Test Accuracy: 0.598\n",
      "Epoch 12, Loss: 1.9742750804475013, Accuracy: 0.65175, Test Loss: 1.9722830802202225, Test Accuracy: 0.6135\n",
      "Epoch 13, Loss: 1.8763344313235992, Accuracy: 0.6684166666666667, Test Loss: 1.8715698048472404, Test Accuracy: 0.6365\n",
      "Epoch 14, Loss: 1.7504700041831809, Accuracy: 0.693, Test Loss: 1.7429593205451965, Test Accuracy: 0.6575\n",
      "Epoch 15, Loss: 1.5962766408920288, Accuracy: 0.7179166666666666, Test Loss: 1.5893241912126541, Test Accuracy: 0.683\n",
      "Epoch 16, Loss: 1.4215264891056305, Accuracy: 0.7451666666666666, Test Loss: 1.4221490323543549, Test Accuracy: 0.698\n",
      "Epoch 17, Loss: 1.2436028148265594, Accuracy: 0.7673333333333333, Test Loss: 1.2562762051820755, Test Accuracy: 0.724\n",
      "Epoch 18, Loss: 1.079925998728326, Accuracy: 0.7865, Test Loss: 1.1107737869024277, Test Accuracy: 0.7515\n",
      "Epoch 19, Loss: 0.9429618481625902, Accuracy: 0.8029166666666666, Test Loss: 0.9938677176833153, Test Accuracy: 0.7615\n",
      "Epoch 20, Loss: 0.833633708827039, Accuracy: 0.81775, Test Loss: 0.8975009731948376, Test Accuracy: 0.788\n",
      "Epoch 21, Loss: 0.7474319047116219, Accuracy: 0.8289166666666666, Test Loss: 0.8227730691432953, Test Accuracy: 0.7995\n",
      "Epoch 22, Loss: 0.6792998630949791, Accuracy: 0.8410833333333333, Test Loss: 0.7602053508162498, Test Accuracy: 0.812\n",
      "Epoch 23, Loss: 0.6261255151413857, Accuracy: 0.8475, Test Loss: 0.7112499754875898, Test Accuracy: 0.8235\n",
      "Epoch 24, Loss: 0.582801970712682, Accuracy: 0.8556666666666667, Test Loss: 0.6746584884822369, Test Accuracy: 0.82\n",
      "Epoch 25, Loss: 0.5475644982875661, Accuracy: 0.8628333333333333, Test Loss: 0.6387217957526445, Test Accuracy: 0.828\n",
      "Epoch 26, Loss: 0.5177671776172963, Accuracy: 0.8673333333333333, Test Loss: 0.6091835051774979, Test Accuracy: 0.8345\n",
      "Epoch 27, Loss: 0.4927649589929175, Accuracy: 0.8718333333333333, Test Loss: 0.5866722874343395, Test Accuracy: 0.841\n",
      "Epoch 28, Loss: 0.4715581279485784, Accuracy: 0.8745833333333334, Test Loss: 0.5650540627539158, Test Accuracy: 0.848\n",
      "Epoch 29, Loss: 0.4527430061964279, Accuracy: 0.8795833333333334, Test Loss: 0.5479993410408497, Test Accuracy: 0.844\n",
      "Epoch 30, Loss: 0.4367815113448082, Accuracy: 0.88225, Test Loss: 0.5313373431563377, Test Accuracy: 0.8535\n",
      "Epoch 31, Loss: 0.42240991078792733, Accuracy: 0.8865833333333333, Test Loss: 0.5171035621315241, Test Accuracy: 0.8525\n",
      "Epoch 32, Loss: 0.4097187576141763, Accuracy: 0.88925, Test Loss: 0.5064368508756161, Test Accuracy: 0.856\n",
      "Epoch 33, Loss: 0.39844909294488584, Accuracy: 0.8904166666666666, Test Loss: 0.49533312395215034, Test Accuracy: 0.856\n",
      "Epoch 34, Loss: 0.38808637223345166, Accuracy: 0.8946666666666667, Test Loss: 0.48242982663214207, Test Accuracy: 0.86\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fa0e75c2a7dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main function: train and test the model\n",
    "EPOCHS = 100\n",
    "test_acc = []\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    test_acc.append(test_accuracy.result())\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print (template.format(epoch+1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result(),\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pylab.figure()\n",
    "pylab.plot(np.arange(EPOCHS), test_acc, label='gradient descent')\n",
    "pylab.xlabel('epochs')\n",
    "pylab.ylabel('test accuracy')\n",
    "pylab.legend(loc='lower right')\n",
    "pylab.savefig('./figures/6.3_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get filters learned at the first conv layer\n",
    "filters_conv1 = model.conv1.get_weights()[0]\n",
    "print(filters_conv1.shape)\n",
    "pylab.figure()\n",
    "pylab.gray()\n",
    "for i in range(32):\n",
    "    pylab.subplot(8, 4, i+1); pylab.axis('off'); pylab.imshow(filters_conv1[:,:,0,i])\n",
    "pylab.savefig('./figures/6.3_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select and show a random sample\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "ind = np.random.randint(0,2000)\n",
    "x = x_test[ind,:]\n",
    "conv1, p1, conv2, p2, out = model(x[tf.newaxis,...])\n",
    "\n",
    "pylab.figure()\n",
    "pylab.gray()\n",
    "pylab.axis('off'); \n",
    "pylab.imshow(x.reshape(28,28))\n",
    "pylab.savefig('./figures/6.3_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display visually the predicted confidence scores\n",
    "utils.show_prob_mnist(np.array(out)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature maps at conv1\n",
    "pylab.figure()\n",
    "pylab.gray()\n",
    "conv1 = np.array(conv1)\n",
    "for i in range(32):\n",
    "    pylab.subplot(4, 8, i+1); pylab.axis('off'); pylab.imshow(conv1[0,:,:,i])\n",
    "pylab.savefig('./figures/6.3_4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature maps at pooling1\n",
    "pylab.figure()\n",
    "pylab.gray()\n",
    "p1 = np.array(p1)\n",
    "for i in range(32):\n",
    "    pylab.subplot(4, 8, i+1); pylab.axis('off'); pylab.imshow(p1[0,:,:,i])\n",
    "pylab.savefig('./figures/6.3_5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature maps at conv2\n",
    "pylab.figure()\n",
    "pylab.gray()\n",
    "conv2 = np.array(conv2)\n",
    "for i in range(64):\n",
    "    pylab.subplot(8, 8, i+1); pylab.axis('off'); pylab.imshow(conv2[0,:,:,i])\n",
    "pylab.savefig('./figures/6.3_6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature maps at pooling2\n",
    "pylab.figure()\n",
    "pylab.gray()\n",
    "p2 = np.array(p2)\n",
    "for i in range(64):\n",
    "    pylab.subplot(8, 8, i+1); pylab.axis('off'); pylab.imshow(p2[0,:,:,i])\n",
    "pylab.savefig('./figures/6.3_7.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
